{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "house pricing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQCzjEXl6XYI",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKoFgXFJHH6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "#read the data\n",
        "import pandas as pd\n",
        "subm=pd.read_csv('/content/sample_data/house pricing/test.csv')\n",
        "data=pd.read_csv('/content/sample_data/house pricing/train.csv')\n",
        "#=======================================\n",
        "#clean the data\n",
        "#clean the data\n",
        "from sklearn.impute import SimpleImputer\n",
        "num=data._get_numeric_data().columns\n",
        "num2=set(subm._get_numeric_data().columns)\n",
        "cat=set(data.columns)-set(num)\n",
        "data.at[:,num]=pd.DataFrame(SimpleImputer(missing_values = np.nan, strategy ='mean').fit(data.loc[:,num]).transform(data.loc[:,num]),columns=num)\n",
        "subm.at[:,num2]=pd.DataFrame(SimpleImputer(missing_values = np.nan, strategy ='mean').fit(subm.loc[:,num2]).transform(subm.loc[:,num2]),columns=num2)\n",
        "data.at[:,cat]=pd.DataFrame(SimpleImputer(missing_values = np.nan, strategy ='most_frequent').fit(data.loc[:,cat]).transform(data.loc[:,cat]),columns=cat)\n",
        "subm.at[:,cat]=pd.DataFrame(SimpleImputer(missing_values = np.nan, strategy ='most_frequent').fit(subm.loc[:,cat]).transform(subm.loc[:,cat]),columns=cat)\n",
        "#=======================================\n",
        "#categorical encoding\n",
        "data=pd.get_dummies(data)\n",
        "subm=pd.get_dummies(subm)\n",
        "#=======================================\n",
        "#feature selection\n",
        "y=data.SalePrice\n",
        "from sklearn.feature_selection import SelectPercentile,chi2\n",
        "#X=pd.DataFrame(SelectPercentile(score_func=chi2,percentile=80).fit_transform(data.drop('SalePrice',1).values,y.values.astype('int')))\n",
        "#data=X\n",
        "#data['SalePrice']=y\n",
        "#=======================================\n",
        "#normalization\n",
        "data['SalePrice']=np.log(data['SalePrice'])\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "y=data['SalePrice']\n",
        "std=y.std()\n",
        "mean=y.mean()\n",
        "data.at[:,:]=StandardScaler(copy=True, with_mean=True, with_std=True).fit_transform(data)\n",
        "subm.at[:,:]=StandardScaler(copy=True, with_mean=True, with_std=True).fit_transform(subm)\n",
        "#=======================================\n",
        "#split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X=data.drop(['SalePrice'],axis=1)\n",
        "y=data['SalePrice']\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=44,shuffle =True)\n",
        "#=======================================\n",
        "#model\n",
        "from sklearn.linear_model import Ridge\n",
        "reg = Ridge(alpha=0.01,) \n",
        "reg.fit(X_train, y_train)\n",
        "#=======================================\n",
        "#metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "y_pred=reg.predict(X_test)\n",
        "print(mean_squared_error(np.exp(y_pred*std+mean),np.exp(y_test*std+mean)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KlL-P0bs15k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}